{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Convention in LIPS to have a more dynamic variable naming\n",
    "This has been done only for power grid use case for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from lips import get_root_path\n",
    "from lips.config.configmanager import ConfigManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIPS_PATH = get_root_path(pathlib_format=True).parent#pathlib.Path().resolve().parent\n",
    "BENCH_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"benchmarks\" / \"l2rpn_case14_sandbox.ini\"\n",
    "SIM_CONFIG_PATH = LIPS_PATH / \"configurations\" / \"powergrid\" / \"simulators\"\n",
    "DATA_PATH = LIPS_PATH / \"reference_data\" / \"powergrid\" / \"l2rpn_case14_sandbox\"\n",
    "LOG_PATH = LIPS_PATH / \"lips_logs.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the config file including the names convention for attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_CONVENTION_CONFIG = LIPS_PATH / \"configurations\" / \"powergrid\" / \"names_convention.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.config.configmanager import ConfigManager\n",
    "\n",
    "config = ConfigManager(NAME_CONVENTION_CONFIG, \"DEFAULT\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the NameConvention class to load the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.dataset.utils.powergrid_utils import NamesConvention\n",
    "\n",
    "my_convention = NamesConvention()\n",
    "print(my_convention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may change the names convention directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convention.input_variables_title = \"attr_x\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also load the names convention from a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convention.set_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convention.todict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use an example to check if everything works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "\n",
    "benchmark = PowerGridBenchmark(benchmark_path=None,\n",
    "                               benchmark_name=\"Benchmark3\",\n",
    "                               config_path=BENCH_CONFIG_PATH,\n",
    "                               load_data_set=False,\n",
    "                               names_convention=my_convention,\n",
    "                               log_path=LOG_PATH\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.generate(nb_sample_train=int(1e2),\n",
    "                   nb_sample_val=int(1e2),\n",
    "                   nb_sample_test=int(1e2),\n",
    "                   nb_sample_test_ood_topo=int(1e2),\n",
    "                   do_store_physics=True,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.train_dataset.data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.augmented_simulators.torch_models.fully_connected import TorchFullyConnected\n",
    "from lips.augmented_simulators.torch_simulator import TorchSimulator\n",
    "from lips.dataset.scaler import StandardScaler\n",
    "\n",
    "torch_sim = TorchSimulator(name=\"torch_fc\",\n",
    "                           model=TorchFullyConnected,\n",
    "                           scaler=StandardScaler,\n",
    "                           log_path=LOG_PATH,\n",
    "                           device=\"cpu\",\n",
    "                           seed=42,\n",
    "                           bench_config_path=BENCH_CONFIG_PATH,\n",
    "                           bench_config_name=\"Benchmark1\",\n",
    "                           sim_config_path=SIM_CONFIG_PATH / \"torch_fc.ini\",\n",
    "                           sim_config_name=\"DEFAULT\" # use the default set of hyper parameters\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim.train(benchmark.train_dataset, benchmark.val_dataset, save_path=None, epochs=20, train_batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics = benchmark.evaluate_simulator(augmented_simulator=torch_sim,\n",
    "                                                 eval_batch_size=128,\n",
    "                                                 dataset=\"all\",\n",
    "                                                 shuffle=False,\n",
    "                                                 save_path=None,\n",
    "                                                 save_predictions=False\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_sim_metrics[\"test\"][\"Physics\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips_irt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
